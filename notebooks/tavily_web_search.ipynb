{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Quem é o Goku?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://dragonball.fandom.com/pt-br/wiki/Goku', 'title': 'Goku | Dragon Ball Wiki Brasil - Fandom', 'content': 'Goku (孫 悟空, Son Gokū, ou Son Goku), nascido Kakarotto (カカロット, Kakarotto) é o protagonista das franquias Dragon Ball. Ele é neto adotivo de Vovô', 'score': 0.8941352, 'raw_content': None}, {'url': 'https://www.instagram.com/reel/DDF_rN7vtR1/?hl=en', 'title': 'O Goku é o personagem menos interessante de Dragon Ball e o ...', 'content': 'Um super-herói gay brasileiro, que ativa seus poderes ouvindo música pop e materializa armas inspiradas em tudo aquilo que marcou a infância', 'score': 0.8827621, 'raw_content': None}, {'url': 'https://pt.wikipedia.org/wiki/Goku', 'title': 'Goku – Wikipédia, a enciclopédia livre', 'content': 'Son Goku (孫悟空, Son Gokū; mais conhecido apenas como Goku), cujo nome de nascimento é Kakarotto (カカロット, Kakarotto), é o protagonista da franquia', 'score': 0.88178825, 'raw_content': None}, {'url': 'https://www.aficionados.com.br/goku-dragon-ball/', 'title': 'Goku: conheça a história do protagonista de Dragon Ball!', 'content': 'Goku é filho de Bardock, um guerreiro Saiyajin pouco popular entre a sua raça, e sua mãe é Gi-ne, tendo nascido no ano de 737 no Planeta Vegeta.', 'score': 0.8706085, 'raw_content': None}, {'url': 'https://en.wikipedia.org/wiki/Goku', 'title': 'Goku - Wikipedia', 'content': 'Goku is introduced as an eccentric, monkey-tailed boy who practices martial arts and possesses superhuman strength. He meets Bulma and joins her on a journey to', 'score': 0.8533396, 'raw_content': None}], 'response_time': 1.03, 'request_id': 'a0502a03-bfa3-4feb-9b67-8c67c0fdac9d'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv                                                  # type: ignore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from tavily import TavilyClient                                                 # type: ignore\n",
    "client = TavilyClient(os.getenv('TAVILY_API_KEY'))\n",
    "response = client.search(query='Quem é o Goku?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking:  Okay, the user is asking about Ollama's new engine. First, I need to check if I have the necessary information. The provided tools include a web_search function, so I should use that.\n",
      "\n",
      "I should start by performing a web search to find the latest updates on Ollama's engine. The user might be interested in information like new features, improvements, or changes in the platform. I need to make sure the search is accurate and covers recent news. Once I get the results, I can summarize the information to answer the user's question effectively.\n",
      "\n",
      "Tool calls:  [ToolCall(function=Function(name='web_search', arguments={'query': 'ollama new engine'}))]\n",
      "Result:  [{'url': 'https://ollama.com/blog/new-model-scheduling', 'title': 'New model scheduling · Ollama Blog', 'content': 'New model scheduling · Ollama Blog [![Image 1: Ollama](https://ollama.com/public/oll...\n",
      "Thinking:  Okay, the user is asking about Ollama's new engine. I need to check the web search results to find the latest information. The first tool call was to search for \"ollama new engine,\" and the response provided some links. Let me look through the content.\n",
      "\n",
      "The first result mentions a new model scheduling system, which is a big update. They also talk about improving memory management to boost GPU usage. Other links mention new features like multi-regex pretokenizers and tensor loading by prefix/suffix. There's also info about multimodal models and compatibility with tools like Code Llama. The user might be interested in the main features like scheduling and memory management, as well as the support for different models.\n",
      "\n",
      "I should summarize the key points: the new engine's improvements in scheduling and memory, support for new models, and the overall goal of enhancing performance. Make sure to mention the main updates clearly and connect them back to the user's question.\n",
      "\n",
      "Content:  Ollama's new engine has introduced several key features to enhance performance and support new models:\n",
      "\n",
      "1. **Improved Model Scheduling**: The engine now measures the exact memory required for models compared to estimates, optimizing GPU utilization for better processing speeds.\n",
      "2. **Memory Management**: The new engine allocates more memory to GPUs, improving token generation and processing speeds across various embedding models.\n",
      "3. **Multimodal Support**: Ollama now supports multimodal models (text + vision, audio, etc.) with enhanced accuracy and reliability.\n",
      "4. **New Features**: Support for multi-regex pretokenizers and tensor loading by prefix/suffix, along with compatibility with tools like Code Llama.\n",
      "\n",
      "These updates aim to improve the efficiency and accuracy of Ollama's local inference capabilities.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv                                                  # type: ignore\n",
    "from tavily import TavilyClient                                                 # type: ignore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tavily = TavilyClient(api_key=os.getenv('TAVILY_API_KEY'))\n",
    "\n",
    "def web_search(query: str): return tavily.search(query)['results']\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "from ollama import chat, web_fetch #, web_search                                # type: ignore\n",
    "\n",
    "\n",
    "available_tools = {'web_search': web_search, 'web_fetch': web_fetch}\n",
    "\n",
    "messages = [{'role': 'user', 'content': \"what is ollama's new engine\"}]\n",
    "\n",
    "while True:\n",
    "\n",
    "    MODEL = 'qwen3:0.6b' #'qwen3:4b'\n",
    "\n",
    "    response = chat(model=MODEL, messages=messages, tools=[web_search], think=True)\n",
    "\n",
    "    if response.message.thinking: print('Thinking: ', response.message.thinking)\n",
    "\n",
    "    if response.message.content: print('Content: ', response.message.content)\n",
    "    \n",
    "    messages.append(response.message)\n",
    "    \n",
    "    if not response.message.tool_calls: break\n",
    "\n",
    "    print('Tool calls: ', response.message.tool_calls)\n",
    "    \n",
    "    for tool_call in response.message.tool_calls: function_to_call = available_tools.get(tool_call.function.name)\n",
    "\n",
    "    if function_to_call:\n",
    "        args = tool_call.function.arguments\n",
    "        result = function_to_call(**args)\n",
    "        print('Result: ', str(result)[:200]+'...')\n",
    "        # Result is truncated for limited context lengths\n",
    "        messages.append({'role': 'tool', 'content': str(result)[:2000 * 4], 'tool_name': tool_call.function.name})\n",
    "    else:\n",
    "        messages.append({'role': 'tool', 'content': f'Tool {tool_call.function.name} not found', 'tool_name': tool_call.function.name})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama-websearch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
