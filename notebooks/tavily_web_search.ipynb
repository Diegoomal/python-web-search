{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv                                                  # type: ignore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from tavily import TavilyClient                                                 # type: ignore\n",
    "client = TavilyClient(os.getenv('TAVILY_API_KEY'))\n",
    "response = client.search(query='Quem Ã© o Goku?')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv                                                  # type: ignore\n",
    "from tavily import TavilyClient                                                 # type: ignore\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tavily = TavilyClient(api_key=os.getenv('TAVILY_API_KEY'))\n",
    "\n",
    "def web_search(query: str): return tavily.search(query)['results']\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "from ollama import chat, web_fetch #, web_search                                # type: ignore\n",
    "\n",
    "\n",
    "available_tools = {'web_search': web_search, 'web_fetch': web_fetch}\n",
    "\n",
    "messages = [{'role': 'user', 'content': \"what is ollama's new engine\"}]\n",
    "\n",
    "while True:\n",
    "\n",
    "    MODEL = 'qwen3:0.6b' #'qwen3:4b'\n",
    "\n",
    "    response = chat(model=MODEL, messages=messages, tools=[web_search], think=True)\n",
    "\n",
    "    if response.message.thinking: print('Thinking: ', response.message.thinking)\n",
    "\n",
    "    if response.message.content: print('Content: ', response.message.content)\n",
    "    \n",
    "    messages.append(response.message)\n",
    "    \n",
    "    if not response.message.tool_calls: break\n",
    "\n",
    "    print('Tool calls: ', response.message.tool_calls)\n",
    "    \n",
    "    for tool_call in response.message.tool_calls: function_to_call = available_tools.get(tool_call.function.name)\n",
    "\n",
    "    if function_to_call:\n",
    "        args = tool_call.function.arguments\n",
    "        result = function_to_call(**args)\n",
    "        print('Result: ', str(result)[:200]+'...')\n",
    "        # Result is truncated for limited context lengths\n",
    "        messages.append({'role': 'tool', 'content': str(result)[:2000 * 4], 'tool_name': tool_call.function.name})\n",
    "    else:\n",
    "        messages.append({'role': 'tool', 'content': f'Tool {tool_call.function.name} not found', 'tool_name': tool_call.function.name})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama-websearch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
